{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook presents the [Initial Data Analysis](#Initial-Data-Analysis) and the [Data Manipulation](#Data-Manipulation) of the New York Times Blog dataset. The first part presents an overview of the data, according to the first course activity. The second part transforms the data in order to improve understanding and results from the analysis. \n",
    "\n",
    "\n",
    "A [Summary](#Summary) is presented at the end of the notebook, as well as the [Concluding Remarks](#Concluding-Remarks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Pandas for Data Frame \n",
    "import numpy as np # NumPy for vetorial operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reads the CSV file using Pandas\n",
    "dataset = pd.read_csv(\"NYTimesBlogTrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting the first 5 rows\n",
    "\n",
    "This initial view shows the attributes available and their content. As the table shows, there is at least one column with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>PubDate</th>\n",
       "      <th>Popular</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>Crosswords/Games</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More School Daze</td>\n",
       "      <td>A puzzle from Ethan Cooper that reminds me tha...</td>\n",
       "      <td>A puzzle from Ethan Cooper that reminds me tha...</td>\n",
       "      <td>508</td>\n",
       "      <td>2014-09-01 22:00:09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New 96-Page Murakami Work Coming in December</td>\n",
       "      <td>The Strange Library will arrive just three and...</td>\n",
       "      <td>The Strange Library will arrive just three and...</td>\n",
       "      <td>285</td>\n",
       "      <td>2014-09-01 21:14:07</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>Public Pension Funds Stay Mum on Corporate Expats</td>\n",
       "      <td>Public pension funds have major stakes in Amer...</td>\n",
       "      <td>Public pension funds have major stakes in Amer...</td>\n",
       "      <td>1211</td>\n",
       "      <td>2014-09-01 21:05:36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>Boot Camp for Bankers</td>\n",
       "      <td>As they struggle to find new business to bolst...</td>\n",
       "      <td>As they struggle to find new business to bolst...</td>\n",
       "      <td>1405</td>\n",
       "      <td>2014-09-01 20:43:34</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science</td>\n",
       "      <td>Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Of Little Help to Older Knees</td>\n",
       "      <td>Middle-aged and older patients are unlikely to...</td>\n",
       "      <td>Middle-aged and older patients are unlikely to...</td>\n",
       "      <td>181</td>\n",
       "      <td>2014-09-01 18:58:51</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsDesk       SectionName SubsectionName  \\\n",
       "0  Business  Crosswords/Games            NaN   \n",
       "1   Culture              Arts            NaN   \n",
       "2  Business      Business Day       Dealbook   \n",
       "3  Business      Business Day       Dealbook   \n",
       "4   Science            Health            NaN   \n",
       "\n",
       "                                            Headline  \\\n",
       "0                                   More School Daze   \n",
       "1       New 96-Page Murakami Work Coming in December   \n",
       "2  Public Pension Funds Stay Mum on Corporate Expats   \n",
       "3                              Boot Camp for Bankers   \n",
       "4                      Of Little Help to Older Knees   \n",
       "\n",
       "                                             Snippet  \\\n",
       "0  A puzzle from Ethan Cooper that reminds me tha...   \n",
       "1  The Strange Library will arrive just three and...   \n",
       "2  Public pension funds have major stakes in Amer...   \n",
       "3  As they struggle to find new business to bolst...   \n",
       "4  Middle-aged and older patients are unlikely to...   \n",
       "\n",
       "                                            Abstract  WordCount  \\\n",
       "0  A puzzle from Ethan Cooper that reminds me tha...        508   \n",
       "1  The Strange Library will arrive just three and...        285   \n",
       "2  Public pension funds have major stakes in Amer...       1211   \n",
       "3  As they struggle to find new business to bolst...       1405   \n",
       "4  Middle-aged and older patients are unlikely to...        181   \n",
       "\n",
       "               PubDate  Popular  UniqueID  \n",
       "0  2014-09-01 22:00:09        1         1  \n",
       "1  2014-09-01 21:14:07        0         2  \n",
       "2  2014-09-01 21:05:36        0         3  \n",
       "3  2014-09-01 20:43:34        1         4  \n",
       "4  2014-09-01 18:58:51        1         5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Presents the top 5 rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the period in which the news were recorded\n",
    "\n",
    "By knowing the period, it is possible to estimate, for future steps, which time features could be used. By the fact that there are data corresponding to 3 months, it possible to discard month as a target for analysis, since there is not data for all months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From 2014-09-01 00:01:32 to 2014-11-30 22:01:45'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracts the minimum and maximum date. By the fact that PubDate is organized in format: \n",
    "# YEAR-MONTH-DAY HOUR:MINUTE:SECOND, the lexicographic order corresponds to the chronological order.\n",
    "\"From {0} to {1}\".format(dataset[\"PubDate\"].min(), dataset[\"PubDate\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting only columns of interest\n",
    "\n",
    "For this initial analysis, only 4 variables will be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a new dataframe using only specific columns\n",
    "sub_dataset = dataset[[\"NewsDesk\", \"SectionName\", \"WordCount\", \"PubDate\", \"Popular\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting the number of null values per column\n",
    "\n",
    "Here we observe with detail for missing value on interest columns. As the results show, *NewsDesk* and *SectionName* contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>Popular</th>\n",
       "      <th>PubDate</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>WordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Null Values</th>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             NewsDesk  Popular  PubDate  SectionName  WordCount\n",
       "Null Values      1846        0        0         2300          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A new data frame is created.For each attribute, the number of null values summed and results in a column\n",
    "empty_values_summary = pd.DataFrame(\n",
    "    {'NewsDesk': sub_dataset['NewsDesk'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'SectionName': sub_dataset['SectionName'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'WordCount': sub_dataset['WordCount'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'PubDate': sub_dataset['PubDate'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'Popular': sub_dataset['Popular'].isnull().apply(lambda x: 1 if x else 0).sum()},\n",
    "      index=['Null Values'])\n",
    "\n",
    "# Presents the dataframe created\n",
    "empty_values_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the information about WordCount\n",
    "\n",
    "The first variable analyzed is *WordCount*. The code below show statistics about the number of words from all publications. As it is possible to observe, there are publications without word and at least one with 10,912 words. In average, the number of words is 546."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6532.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>524.434323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>546.153272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>374.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>723.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10912.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          WordCount\n",
       "count   6532.000000\n",
       "mean     524.434323\n",
       "std      546.153272\n",
       "min        0.000000\n",
       "25%      187.000000\n",
       "50%      374.000000\n",
       "75%      723.250000\n",
       "max    10912.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only WordCount and use describe function to extract the main statistics from values.\n",
    "sub_dataset[['WordCount']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the number of publications without words\n",
    "\n",
    "To better estimate the number of publications without words, a specific count is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selects only records with WordCount equals to 0 and count the number\n",
    "sub_dataset[ sub_dataset['WordCount'] == 0 ]['WordCount'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting the distribuition of NewsDesk values\n",
    "\n",
    "*NewsDesk* is the category of a publication. The code below shows the percentage of publications for each *NewsDesk* value. The most frequent category is **Business**, while the less frequent is **Sports**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business    0.236987\n",
       "TStyle      0.110839\n",
       "Culture     0.103491\n",
       "OpEd        0.079761\n",
       "Foreign     0.057410\n",
       "Styles      0.045468\n",
       "Metro       0.030312\n",
       "Science     0.029700\n",
       "Travel      0.017759\n",
       "Magazine    0.004746\n",
       "National    0.000612\n",
       "Sports      0.000306\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset['NewsDesk'].value_counts(sort=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing the distribuition of NewsDesk values by Popularity\n",
    "\n",
    "The code above showed, proportionally, the number of publications by *NewsDesk*. Now we analyze, for each *NewsDesk*, the division between popular (indicated by *1*) and impopular (indicated by *0*) entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsDesk  Popular\n",
       "Business  0          1301\n",
       "          1           247\n",
       "Culture   0           626\n",
       "          1            50\n",
       "Foreign   0           372\n",
       "          1             3\n",
       "Magazine  0            31\n",
       "Metro     0           181\n",
       "          1            17\n",
       "National  0             4\n",
       "OpEd      0           113\n",
       "          1           408\n",
       "Science   0            73\n",
       "          1           121\n",
       "Sports    0             2\n",
       "Styles    0           196\n",
       "          1           101\n",
       "TStyle    0           715\n",
       "          1             9\n",
       "Travel    0           115\n",
       "          1             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groups records by NewsDesk and Popular and counts the number of values\n",
    "sub_dataset.groupby([\"NewsDesk\", \"Popular\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing the distribution of SectionName values by Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsDesk  SectionName       Popular\n",
       "Business  Business Day      0          998\n",
       "                            1           93\n",
       "          Crosswords/Games  0           19\n",
       "                            1          103\n",
       "          Technology        0          280\n",
       "                            1           50\n",
       "Culture   Arts              0          625\n",
       "                            1           50\n",
       "Foreign   World             0          209\n",
       "                            1            3\n",
       "Magazine  Magazine          0           31\n",
       "Metro     N.Y. / Region     0          181\n",
       "                            1           17\n",
       "National  U.S.              0            2\n",
       "OpEd      Opinion           0          113\n",
       "                            1          407\n",
       "Science   Health            0           73\n",
       "                            1          119\n",
       "Sports    Sports            0            1\n",
       "Styles    Health            0            1\n",
       "          Style             0            2\n",
       "          U.S.              0           77\n",
       "                            1          100\n",
       "Travel    Travel            0          115\n",
       "                            1            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groups the records by NewsDesk, SectionName and Popular and counts the number of values\n",
    "sub_dataset.groupby([\"NewsDesk\", \"SectionName\", \"Popular\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing SectionNames distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business Day        0.167177\n",
       "Arts                0.103337\n",
       "Opinion             0.092927\n",
       "U.S.                0.077312\n",
       "Technology          0.050521\n",
       "World               0.032456\n",
       "N.Y. / Region       0.030312\n",
       "Health              0.029700\n",
       "Multimedia          0.021586\n",
       "Crosswords/Games    0.018830\n",
       "Travel              0.017912\n",
       "Magazine            0.004746\n",
       "Open                0.000612\n",
       "Style               0.000306\n",
       "Sports              0.000153\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset['SectionName'].value_counts(sort=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Popular distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.83267\n",
       "1    0.16733\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset['Popular'].value_counts(sort=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation\n",
    "\n",
    "In this section some data preparation steps are performed to segment and extract information from dataset attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first manipulation performed is binning (or segmenting) the *WordCount* variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Avoid a warning that incorrecly appears when performing the assignment below.\n",
    "pd.options.mode.chained_assignment = None\n",
    "# Create WordCountBins with 7 bins\n",
    "sub_dataset['WordCountBins'] = pd.cut(sub_dataset['WordCount'], bins = [0, 1, 128, 256, 512, 1024, 2048, 1048576], include_lowest=True, right=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result of the binning, the distribution is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]               92\n",
       "(1, 128]           1006\n",
       "(128, 256]         1253\n",
       "(256, 512]         1770\n",
       "(512, 1024]        1583\n",
       "(1024, 2048]        705\n",
       "(2048, 1048576]     123\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset['WordCountBins'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to analyze if time properties have influence on the popularity, we will extract some features from *PubDate*.\n",
    "\n",
    "The features extracted are: *Day*, *Hour* and *Week Day* and a field that indicates if the publication was perfomed in a weekend or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert PubDate to Datetime Index\n",
    "datetime_index = pd.DatetimeIndex(sub_dataset[\"PubDate\"])\n",
    "\n",
    "# Extract features from DateTime\n",
    "sub_dataset[\"PubMonth\"] = datetime_index.month\n",
    "sub_dataset[\"PubWeekday\"] = datetime_index.weekday\n",
    "sub_dataset[\"PubDay\"] = datetime_index.day\n",
    "sub_dataset[\"PubHour\"] = datetime_index.hour\n",
    "\n",
    "# Indicates with True if the Week Day is Saturday (5) or Sunday (6)\n",
    "sub_dataset[\"IsWeekend\"] = sub_dataset[\"PubWeekday\"].apply(lambda wd: wd in [5, 6] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The news distribution across months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PubMonth\n",
       "9     2341\n",
       "10    2382\n",
       "11    1809\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset.groupby([\"PubMonth\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The news distribution across week days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PubWeekday\n",
       "0    1224\n",
       "1    1190\n",
       "2    1224\n",
       "3    1228\n",
       "4    1164\n",
       "5     190\n",
       "6     312\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset.groupby([\"PubWeekday\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The news distribution across days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PubDay\n",
       "1     150\n",
       "2     211\n",
       "3     266\n",
       "4     204\n",
       "5     200\n",
       "6     231\n",
       "7     218\n",
       "8     212\n",
       "9     208\n",
       "10    295\n",
       "11    172\n",
       "12    199\n",
       "13    199\n",
       "14    213\n",
       "15    207\n",
       "16    202\n",
       "17    282\n",
       "18    192\n",
       "19    205\n",
       "20    222\n",
       "21    245\n",
       "22    236\n",
       "23    246\n",
       "24    298\n",
       "25    202\n",
       "26    202\n",
       "27    145\n",
       "28    148\n",
       "29    220\n",
       "30    208\n",
       "31     94\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset.groupby([\"PubDay\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The news distribution across hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PubHour\n",
       "0     125\n",
       "1      28\n",
       "2      24\n",
       "3      60\n",
       "4     171\n",
       "5     251\n",
       "6     220\n",
       "7     394\n",
       "8     338\n",
       "9     316\n",
       "10    384\n",
       "11    507\n",
       "12    522\n",
       "13    447\n",
       "14    452\n",
       "15    438\n",
       "16    456\n",
       "17    400\n",
       "18    329\n",
       "19    193\n",
       "20    158\n",
       "21    110\n",
       "22    142\n",
       "23     67\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset.groupby([\"PubHour\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The news distribution across business days and weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsWeekend\n",
       "False    6030\n",
       "True      502\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset.groupby([\"IsWeekend\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we analyze if any of the new variables contains null values. Based on the fact that *WordCount* and *PubDate* do not contain null values, the columns derived from them also do not contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>Popular</th>\n",
       "      <th>PubDay</th>\n",
       "      <th>PubHour</th>\n",
       "      <th>PubMonth</th>\n",
       "      <th>PubWeekday</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>WordCountBins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Null Values</th>\n",
       "      <td>0</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             IsWeekend  NewsDesk  Popular  PubDay  PubHour  PubMonth  \\\n",
       "Null Values          0      1846        0       0        0         0   \n",
       "\n",
       "             PubWeekday  SectionName  WordCount  WordCountBins  \n",
       "Null Values           0         2300          0              0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A new data frame is created.For each attribute, the number of null values summed and results in a column\n",
    "empty_values_summary = pd.DataFrame(\n",
    "    {'NewsDesk': sub_dataset['NewsDesk'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'SectionName': sub_dataset['SectionName'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'WordCount': sub_dataset['WordCount'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'Popular': sub_dataset['Popular'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'WordCountBins': sub_dataset['WordCountBins'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'PubMonth': sub_dataset['PubMonth'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'PubWeekday': sub_dataset['PubWeekday'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'PubDay': sub_dataset['PubDay'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'PubHour': sub_dataset['PubHour'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'IsWeekend': sub_dataset['IsWeekend'].isnull().apply(lambda x: 1 if x else 0).sum()},\n",
    "     index=['Null Values'])\n",
    "\n",
    "# Presents the dataframe created\n",
    "empty_values_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The original variable analyzes showed us that:\n",
    " * **WordCount**: does not contain null values, but has 88 zero values. The values ranges from 0 to 10912 words. Since it is a numeric attribute, it makes sense to analyze the frequency values by the distribution statistics. The *mean* is 524.43 and the *standard deviation* is 546.15. \n",
    " * **NewsDesk**: there are 12 *NewsDesk* values. The three most common are *Business* (23%), *TStyle* (11%) and *Culture* (10%). From all entries, there are 1846 missing *NewsDesk* values.\n",
    " * **SectionName**: there are 14 *SectionName* in the dataset. Some of them a related to more than one *NewsDesk* (e.g. *U.S.* is related to *National* and *Styles*). The three most frequent entries are *Business Day* (16%), *Arts* (10%) and *Opinion* (9%). There are 2300 missing values.\n",
    " * **Popularity**: is contains only 2 values: *0* and *1*. Since it is used as a dependent variable on the dataset, it does not contain any missing value. Only 16% of the records are popular.\n",
    " \n",
    " The analysis of the new attributes indicated the absence of null values. Individually, it is possible to observe that:\n",
    " * **WordCountBins**: contains 7 values. The distribution if from 92 to 1770 value per bin.\n",
    " * **PubMonth**: contains 3 month, each of which contains about 2000 records.\n",
    " * **PubWeekDay**: naturally contains 7 values. Business days contains about 1000 records, while each weekend day contains less than 400.\n",
    " * **PubDay**: contains 31 days. Except for the 31th day, which contains 95 days, the days contains about 200 records.\n",
    " * **PubHour**: contains 24 hours. The period between 7 and 18 hours contains the higher number of records.\n",
    " * **IsWeekend**: as indicated by the PubWeekDay distrubution, business days contains the majority of records (6030), while weekends contains 502."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding Remarks\n",
    "\n",
    "In this activity the New York Time blog dataset was analyzed and some attributes were manipulated to segment and extract features. \n",
    "\n",
    "The original attributes analyzed were:\n",
    " * WordCount\n",
    " * NewsDesk\n",
    " * SectionName \n",
    " * Popularity\n",
    " * PubDate\n",
    " \n",
    " The new attributes created were:\n",
    " \n",
    " * WordCountBins bin.\n",
    " * PubMonth\n",
    " * PubWeekDay\n",
    " * PubDay\n",
    " * PubHour\n",
    " * IsWeekend\n",
    " \n",
    "It is also possible to analyze the textual content, such as snippet and abstract, to observe the content influence on the publication popularity. However, this step will be left for remaining course modules to avoid creating a overly extensive notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
