{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring New York Times blog dataset\n",
    "\n",
    "The goal of this notebook is perform the initial analysis of the New York Time blog dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Pandas for Data Frame \n",
    "import numpy as np # NumPy for vetorial operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reads the CSV file using Pandas\n",
    "dataset = pd.read_csv(\"NYTimesBlogTrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting the first 5 rows\n",
    "\n",
    "This initial view shows the attributes available and their content. As the table shows, there is at least one column with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>PubDate</th>\n",
       "      <th>Popular</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>Crosswords/Games</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More School Daze</td>\n",
       "      <td>A puzzle from Ethan Cooper that reminds me tha...</td>\n",
       "      <td>A puzzle from Ethan Cooper that reminds me tha...</td>\n",
       "      <td>508</td>\n",
       "      <td>2014-09-01 22:00:09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New 96-Page Murakami Work Coming in December</td>\n",
       "      <td>The Strange Library will arrive just three and...</td>\n",
       "      <td>The Strange Library will arrive just three and...</td>\n",
       "      <td>285</td>\n",
       "      <td>2014-09-01 21:14:07</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>Public Pension Funds Stay Mum on Corporate Expats</td>\n",
       "      <td>Public pension funds have major stakes in Amer...</td>\n",
       "      <td>Public pension funds have major stakes in Amer...</td>\n",
       "      <td>1211</td>\n",
       "      <td>2014-09-01 21:05:36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>Boot Camp for Bankers</td>\n",
       "      <td>As they struggle to find new business to bolst...</td>\n",
       "      <td>As they struggle to find new business to bolst...</td>\n",
       "      <td>1405</td>\n",
       "      <td>2014-09-01 20:43:34</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science</td>\n",
       "      <td>Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Of Little Help to Older Knees</td>\n",
       "      <td>Middle-aged and older patients are unlikely to...</td>\n",
       "      <td>Middle-aged and older patients are unlikely to...</td>\n",
       "      <td>181</td>\n",
       "      <td>2014-09-01 18:58:51</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsDesk       SectionName SubsectionName  \\\n",
       "0  Business  Crosswords/Games            NaN   \n",
       "1   Culture              Arts            NaN   \n",
       "2  Business      Business Day       Dealbook   \n",
       "3  Business      Business Day       Dealbook   \n",
       "4   Science            Health            NaN   \n",
       "\n",
       "                                            Headline  \\\n",
       "0                                   More School Daze   \n",
       "1       New 96-Page Murakami Work Coming in December   \n",
       "2  Public Pension Funds Stay Mum on Corporate Expats   \n",
       "3                              Boot Camp for Bankers   \n",
       "4                      Of Little Help to Older Knees   \n",
       "\n",
       "                                             Snippet  \\\n",
       "0  A puzzle from Ethan Cooper that reminds me tha...   \n",
       "1  The Strange Library will arrive just three and...   \n",
       "2  Public pension funds have major stakes in Amer...   \n",
       "3  As they struggle to find new business to bolst...   \n",
       "4  Middle-aged and older patients are unlikely to...   \n",
       "\n",
       "                                            Abstract  WordCount  \\\n",
       "0  A puzzle from Ethan Cooper that reminds me tha...        508   \n",
       "1  The Strange Library will arrive just three and...        285   \n",
       "2  Public pension funds have major stakes in Amer...       1211   \n",
       "3  As they struggle to find new business to bolst...       1405   \n",
       "4  Middle-aged and older patients are unlikely to...        181   \n",
       "\n",
       "               PubDate  Popular  UniqueID  \n",
       "0  2014-09-01 22:00:09        1         1  \n",
       "1  2014-09-01 21:14:07        0         2  \n",
       "2  2014-09-01 21:05:36        0         3  \n",
       "3  2014-09-01 20:43:34        1         4  \n",
       "4  2014-09-01 18:58:51        1         5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Presents the top 5 rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the period in which the news were recorded\n",
    "\n",
    "By knowing the period, it is possible to estimate, for future steps, which time features could be used. By the fact that there are data corresponding to 3 months, it possible to discard month as a target for analysis, since there is not data for all months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From 2014-09-01 00:01:32 to 2014-11-30 22:01:45'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracts the minimum and maximum date. By the fact that PubDate is organized in format: \n",
    "# YEAR-MONTH-DAY HOUR:MINUTE:SECOND, the lexicographic order corresponds to the chronological order.\n",
    "\"From {0} to {1}\".format(dataset[\"PubDate\"].min(), dataset[\"PubDate\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting only columns of interest\n",
    "\n",
    "For this initial analysis, only 4 variables will be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a new dataframe using only specific columns\n",
    "sub_dataset = dataset[[\"NewsDesk\", \"SectionName\", \"WordCount\", \"Popular\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting the number of null values per column\n",
    "\n",
    "Here we observe with detail for missing value on interest columns. As the results show, *NewsDesk* and *SectionName* contains missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Null Values</th>\n",
       "      <td>1846</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             NewsDesk  SectionName  WordCount  Popular\n",
       "Null Values      1846         2300          0        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A new data frame is created.For each attribute, the number of null values summed and results in a column\n",
    "empty_values_summary = pd.DataFrame(\n",
    "    {'NewsDesk': sub_dataset['NewsDesk'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'SectionName': sub_dataset['SectionName'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'WordCount': sub_dataset['WordCount'].isnull().apply(lambda x: 1 if x else 0).sum(),\n",
    "     'Popular': sub_dataset['Popular'].isnull().apply(lambda x: 1 if x else 0).sum()},\n",
    "      index=['Null Values'], columns=[\"NewsDesk\", \"SectionName\", \"WordCount\", \"Popular\"])\n",
    "\n",
    "# Presents the dataframe created\n",
    "empty_values_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the information about WordCount\n",
    "\n",
    "The first variable analyzed is *WordCount*. The code below show statistics about the number of words from all publications. As it is possible to observe, there are publications without word and at least one with 10,912 words. In average, the number of words is 546."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6532.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>524.434323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>546.153272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>374.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>723.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10912.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          WordCount\n",
       "count   6532.000000\n",
       "mean     524.434323\n",
       "std      546.153272\n",
       "min        0.000000\n",
       "25%      187.000000\n",
       "50%      374.000000\n",
       "75%      723.250000\n",
       "max    10912.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only WordCount and use describe function to extract the main statistics from values.\n",
    "sub_dataset[['WordCount']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the number of publications without words\n",
    "\n",
    "To better estimate the number of publications without words, a specific count is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selects only records with WordCount equals to 0 and count the number\n",
    "sub_dataset[ sub_dataset['WordCount'] == 0 ]['WordCount'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting the distribuition of NewsDesk values\n",
    "\n",
    "*NewsDesk* is the category of a publication. The code below shows the percentage of publications for each *NewsDesk* value. The most frequent category is **Business**, while the less frequent is **Sports**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business    0.236987\n",
       "TStyle      0.110839\n",
       "Culture     0.103491\n",
       "OpEd        0.079761\n",
       "Foreign     0.057410\n",
       "Styles      0.045468\n",
       "Metro       0.030312\n",
       "Science     0.029700\n",
       "Travel      0.017759\n",
       "Magazine    0.004746\n",
       "National    0.000612\n",
       "Sports      0.000306\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset['NewsDesk'].value_counts(sort=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing the distribuition of NewsDesk values by Popularity\n",
    "\n",
    "The code above showed, proportionally, the number of publications by *NewsDesk*. Now we analyze, for each *NewsDesk*, the division between popular (indicated by *1*) and impopular (indicated by *0*) entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsDesk  Popular\n",
       "Business  0          1301\n",
       "          1           247\n",
       "Culture   0           626\n",
       "          1            50\n",
       "Foreign   0           372\n",
       "          1             3\n",
       "Magazine  0            31\n",
       "Metro     0           181\n",
       "          1            17\n",
       "National  0             4\n",
       "OpEd      0           113\n",
       "          1           408\n",
       "Science   0            73\n",
       "          1           121\n",
       "Sports    0             2\n",
       "Styles    0           196\n",
       "          1           101\n",
       "TStyle    0           715\n",
       "          1             9\n",
       "Travel    0           115\n",
       "          1             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groups records by NewsDesk and Popular and counts the number of values\n",
    "sub_dataset.groupby([\"NewsDesk\", \"Popular\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing the distribution of SectionName values by Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsDesk  SectionName       Popular\n",
       "Business  Business Day      0          998\n",
       "                            1           93\n",
       "          Crosswords/Games  0           19\n",
       "                            1          103\n",
       "          Technology        0          280\n",
       "                            1           50\n",
       "Culture   Arts              0          625\n",
       "                            1           50\n",
       "Foreign   World             0          209\n",
       "                            1            3\n",
       "Magazine  Magazine          0           31\n",
       "Metro     N.Y. / Region     0          181\n",
       "                            1           17\n",
       "National  U.S.              0            2\n",
       "OpEd      Opinion           0          113\n",
       "                            1          407\n",
       "Science   Health            0           73\n",
       "                            1          119\n",
       "Sports    Sports            0            1\n",
       "Styles    Health            0            1\n",
       "          Style             0            2\n",
       "          U.S.              0           77\n",
       "                            1          100\n",
       "Travel    Travel            0          115\n",
       "                            1            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groups the records by NewsDesk, SectionName and Popular and counts the number of values\n",
    "sub_dataset.groupby([\"NewsDesk\", \"SectionName\", \"Popular\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing SectionNames distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business Day        0.167177\n",
       "Arts                0.103337\n",
       "Opinion             0.092927\n",
       "U.S.                0.077312\n",
       "Technology          0.050521\n",
       "World               0.032456\n",
       "N.Y. / Region       0.030312\n",
       "Health              0.029700\n",
       "Multimedia          0.021586\n",
       "Crosswords/Games    0.018830\n",
       "Travel              0.017912\n",
       "Magazine            0.004746\n",
       "Open                0.000612\n",
       "Style               0.000306\n",
       "Sports              0.000153\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset['SectionName'].value_counts(sort=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Popular distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.83267\n",
       "1    0.16733\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dataset['Popular'].value_counts(sort=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The variable analyzes showed us that:\n",
    " * **WordCount**: does not contain null values, but has 88 zero values. The values ranges from 0 to 10912 words. Since it is a numeric attribute, it makes sense to analyze the frequency values by the distribution statistics. The *mean* is 524.43 and the *standard deviation* is 546.15. \n",
    " * **NewsDesk**: there are 12 *NewsDesk* values. The three most common are *Business* (23%), *TStyle* (11%) and *Culture* (10%). From all entries, there are 1846 missing *NewsDesk* values.\n",
    " * **SectionName**: there are 14 *SectionName* in the dataset. Some of them a related to more than one *NewsDesk* (e.g. *U.S.* is related to *National* and *Styles*). The three most frequent entries are *Business Day* (16%), *Arts* (10%) and *Opinion* (9%). There are 2300 missing values.\n",
    " * **Popularity**: is contains only 2 values: *0* and *1*. Since it is used as a dependent variable on the dataset, it does not contain any missing value. Only 16% of the records are popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding Remarks\n",
    "\n",
    "In this activity the New York Time blog dataset was analyzed. Considering the goal of performing an overview of the data and computing the frequency of some items of interest, no data manipulation was performed. \n",
    "\n",
    "The attributes analyzed were: \n",
    " * WordCount\n",
    " * NewsDesk\n",
    " * SectionName \n",
    " * Popularity\n",
    " \n",
    "On the next task some features should be extracted, such as week day and hour from *PubDate*. It is also possible to analyze the textual content, such as snippet and abstract, to observe the content influence on the publication popularity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
